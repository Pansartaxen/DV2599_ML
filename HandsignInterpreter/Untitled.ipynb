{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3e43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336fecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Returns the data as a pandas dataframe\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('training_data/sign_mnist_train.csv')\n",
    "    except:\n",
    "        df = pd.read_csv(r'HandsignInterpreter\\training_data\\sign_mnist_train.csv')\n",
    "    return df\n",
    "\n",
    "def get_test_data():\n",
    "    \"\"\"Returns the data as a pandas dataframe\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('training_data/sign_mnist_test.csv')\n",
    "    except:\n",
    "        df = pd.read_csv(r'HandsignInterpreter\\training_data\\sign_mnist_test.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a85c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_train():\n",
    "    df = get_data()\n",
    "    df_test = get_test_data()\n",
    "    classes_train = df['label']\n",
    "    classes_test = df_test['label']\n",
    "    del df['label']\n",
    "    del df_test['label']\n",
    "\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    classes_train = label_binarizer.fit_transform(classes_train)\n",
    "    classes_test = label_binarizer.fit_transform(classes_test)\n",
    "\n",
    "    vector_train = df.values\n",
    "    vector_test = df_test.values\n",
    "    vector_train = vector_train / 255\n",
    "    vector_test = vector_test / 255\n",
    "    vector_train = vector_train.reshape(-1, 28, 28, 1)\n",
    "    vector_test = vector_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    datagen.fit(vector_train)\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "    model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "    model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 512 , activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units = 24 , activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(datagen.flow(vector_train, classes_train, batch_size = 128), epochs = 20, validation_data = (vector_test, classes_test), callbacks = [learning_rate_reduction])\n",
    "    print(\"Accuracy of the model is - \" , model.evaluate(vector_test, classes_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348f2ea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 75)       300       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 75)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 25)         100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                12312     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,049\n",
      "Trainable params: 263,749\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:54:20.059786: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "215/215 [==============================] - 29s 133ms/step - loss: 1.0417 - accuracy: 0.6746 - val_loss: 3.6133 - val_accuracy: 0.1141 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "215/215 [==============================] - 30s 141ms/step - loss: 0.2021 - accuracy: 0.9352 - val_loss: 0.9174 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "215/215 [==============================] - 31s 145ms/step - loss: 0.0902 - accuracy: 0.9721 - val_loss: 0.1569 - val_accuracy: 0.9509 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "215/215 [==============================] - 32s 150ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.1929 - val_accuracy: 0.9364 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "215/215 [==============================] - 33s 153ms/step - loss: 0.0406 - accuracy: 0.9862 - val_loss: 0.0253 - val_accuracy: 0.9919 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "215/215 [==============================] - 32s 149ms/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 0.0221 - val_accuracy: 0.9941 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "215/215 [==============================] - 33s 154ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 0.0902 - val_accuracy: 0.9717 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "215/215 [==============================] - 34s 160ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0438 - val_accuracy: 0.9835 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "215/215 [==============================] - 36s 165ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0049 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "215/215 [==============================] - 36s 167ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0211 - val_accuracy: 0.9933 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "215/215 [==============================] - 33s 154ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0317 - val_accuracy: 0.9911 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "215/215 [==============================] - 33s 154ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0066 - val_accuracy: 0.9965 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9983\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "215/215 [==============================] - 38s 174ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0093 - val_accuracy: 0.9957 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "215/215 [==============================] - 40s 185ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0037 - val_accuracy: 0.9985 - lr: 1.2500e-04\n",
      "Epoch 15/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9988\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "215/215 [==============================] - 39s 182ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0018 - val_accuracy: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "215/215 [==============================] - 41s 191ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0069 - val_accuracy: 0.9958 - lr: 6.2500e-05\n",
      "Epoch 17/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "215/215 [==============================] - 42s 196ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0033 - val_accuracy: 0.9982 - lr: 6.2500e-05\n",
      "Epoch 18/20\n",
      "215/215 [==============================] - 41s 192ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0025 - val_accuracy: 0.9993 - lr: 3.1250e-05\n",
      "Epoch 19/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "215/215 [==============================] - 43s 202ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9983 - lr: 3.1250e-05\n",
      "Epoch 20/20\n",
      "215/215 [==============================] - 45s 209ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0034 - val_accuracy: 0.9978 - lr: 1.5625e-05\n",
      "225/225 [==============================] - 8s 35ms/step - loss: 0.0034 - accuracy: 0.9978\n",
      "Accuracy of the model is -  99.77691173553467 %\n"
     ]
    }
   ],
   "source": [
    "cnn_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
