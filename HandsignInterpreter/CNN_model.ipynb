{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3e43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336fecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Returns the data as a pandas dataframe\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('training_data/sign_mnist_train.csv')\n",
    "    except:\n",
    "        df = pd.read_csv(r'HandsignInterpreter\\training_data\\sign_mnist_train.csv')\n",
    "    return df\n",
    "\n",
    "def get_test_data():\n",
    "    \"\"\"Returns the data as a pandas dataframe\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('training_data/sign_mnist_test.csv')\n",
    "    except:\n",
    "        df = pd.read_csv(r'HandsignInterpreter\\training_data\\sign_mnist_test.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a85c2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 75)       300       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 75)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 25)         100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                12312     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,049\n",
      "Trainable params: 263,749\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 14:50:44.367116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "215/215 [==============================] - 31s 141ms/step - loss: 1.0394 - accuracy: 0.6719 - val_loss: 3.4429 - val_accuracy: 0.2163 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "215/215 [==============================] - 31s 146ms/step - loss: 0.2292 - accuracy: 0.9238 - val_loss: 1.6517 - val_accuracy: 0.5213 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "215/215 [==============================] - 31s 144ms/step - loss: 0.1068 - accuracy: 0.9647 - val_loss: 0.1262 - val_accuracy: 0.9636 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "215/215 [==============================] - 32s 149ms/step - loss: 0.0689 - accuracy: 0.9783 - val_loss: 0.1801 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "215/215 [==============================] - 33s 151ms/step - loss: 0.0500 - accuracy: 0.9840 - val_loss: 0.0538 - val_accuracy: 0.9803 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "215/215 [==============================] - 32s 147ms/step - loss: 0.0391 - accuracy: 0.9873 - val_loss: 0.0172 - val_accuracy: 0.9962 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "215/215 [==============================] - 32s 149ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0161 - val_accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9903\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "215/215 [==============================] - 33s 154ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0243 - val_accuracy: 0.9912 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "215/215 [==============================] - 35s 162ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.0086 - val_accuracy: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "215/215 [==============================] - 35s 163ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0624 - val_accuracy: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9962\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "215/215 [==============================] - 35s 165ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0161 - val_accuracy: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "215/215 [==============================] - 34s 157ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0077 - val_accuracy: 0.9968 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "215/215 [==============================] - 32s 148ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0024 - val_accuracy: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "215/215 [==============================] - 33s 155ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0047 - val_accuracy: 0.9993 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "215/215 [==============================] - 36s 166ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0030 - val_accuracy: 0.9996 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "215/215 [==============================] - 35s 161ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0186 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "215/215 [==============================] - 35s 164ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0079 - val_accuracy: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "215/215 [==============================] - 34s 159ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0014 - val_accuracy: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 19/20\n",
      "192/215 [=========================>....] - ETA: 3s - loss: 0.0047 - accuracy: 0.9987"
     ]
    }
   ],
   "source": [
    "df = get_data()\n",
    "df_test = get_test_data()\n",
    "classes_train = df['label']\n",
    "classes_test = df_test['label']\n",
    "del df['label']\n",
    "del df_test['label']\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "classes_train = label_binarizer.fit_transform(classes_train)\n",
    "classes_test = label_binarizer.fit_transform(classes_test)\n",
    "\n",
    "vector_train = df.values\n",
    "vector_test = df_test.values\n",
    "vector_train = vector_train / 255\n",
    "vector_test = vector_test / 255\n",
    "vector_train = vector_train.reshape(-1, 28, 28, 1)\n",
    "vector_test = vector_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(vector_train)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 24 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(datagen.flow(vector_train, classes_train, batch_size = 128), epochs = 20, validation_data = (vector_test, classes_test), callbacks = [learning_rate_reduction])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(vector_test, classes_test)[1]*100 , \"%\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176fd571",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img = plt.imread('hand.png')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img_array = image.img_to_array(img)\n",
    "img_batch = np.expand_dims(img, axis=0)\n",
    "print('Array',img_array.shape,'Batch',img_batch.shape,'Image',img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "img_preprocessed = preprocess_input(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d526a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e22607",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = list(prediction[0])\n",
    "for num in pred:\n",
    "    num = num.item()\n",
    "sorted_pred = sorted(pred, reverse=True)\n",
    "print(sorted_pred)\n",
    "print(pred)\n",
    "index = pred.index(sorted_pred[0])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf17c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
